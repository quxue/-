{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tearRate': {'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'presbyopic': 'no lenses', 'pre': 'no lenses', 'young': 'hard'}}, 'myope': 'hard'}}, 'no': {'age': {'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}}, 'pre': 'soft', 'young': 'soft'}}}}, 'reduced': 'no lenses'}}\n",
      "no lenses\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "import pickle\n",
    "import operator\n",
    "#计算基础香农熵\n",
    "def calcShannonEnt(dateSet):\n",
    "    numEntries = len(dateSet)\n",
    "    labelCounts = {}\n",
    "#判断是正类，还是负类，提取的是yes 和 no\n",
    "    for featVec in dateSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        labelCounts[currentLabel] = labelCounts.get(currentLabel,0)+1\n",
    "#求香农熵\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob*log(prob,2)\n",
    "    return shannonEnt\n",
    "#划分数据集\n",
    "def splitDateSet(dateSet,axis,value):\n",
    "    retDateSet = []\n",
    "    for featVec in dateSet:\n",
    "        if featVec[axis] == value:\n",
    "            #不包含特征axis\n",
    "            reducedFeatVec=featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDateSet.append(reducedFeatVec)\n",
    "    return retDateSet\n",
    "#选择最好的划分数据集的方式，即信息增益最大的特征，作为根特征\n",
    "def chooseBestFeatureToSplit(dateSet):\n",
    "    numberFeatures = len(dateSet[0]) - 1#特征个数\n",
    "    baseEntropy = calcShannonEnt(dateSet)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    #遍历每一个特征,把每个样本中的对应特征挨个提取出来\n",
    "    for i in range(numberFeatures):\n",
    "        featList = [example[i] for example in dateSet]\n",
    "        uniqueVals = set(featList) #某一个特征的取值列表\n",
    "        newEntropy = 0.0\n",
    "        #求各个不同x的值分别的熵，再相加\n",
    "        for value in uniqueVals:\n",
    "            subDateSet = splitDateSet(dateSet,i,value)\n",
    "            prob = len(subDateSet)/float(len(dateSet))#每一个xi都要取到\n",
    "            newEntropy += prob * calcShannonEnt(subDateSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if infoGain > bestInfoGain:\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature =i\n",
    "    return bestFeature\n",
    "#计算正类和负类的出现频率，返回出现频率最高的标签，当遍历完所有属性后，用多数表决来判断该叶节点是正类还是负类\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        classCount[vote] = classCount.get(vote,0)+1\n",
    "    sortedClassCount = sorted(classCount.items(),key = lambda x:x[1],reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "#创建决策树\n",
    "def creatDateTree(dateSet,labels):\n",
    "    classList = [example[-1] for example in dateSet]\n",
    "     #具有相同的分支，不能再通过yes或者no来区别了\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    #属性遍历完了\n",
    "    if len(dateSet[0]) ==1:\n",
    "        return majorityCnt[classList]\n",
    "    bestFeat = chooseBestFeatureToSplit(dateSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}#用字典类型储存决策树，字典的一对多的实现，用子字典充当字典的value,不允许值重复\n",
    "    copyLabels = labels[:]\n",
    "    del(copyLabels[bestFeat]) #用过的特性就不用了，标签删掉\n",
    "    featValues = [example[bestFeat] for example in dateSet]\n",
    "    uniqueValues = set(featValues)\n",
    "    for value in uniqueValues:\n",
    "        subLabels = copyLabels\n",
    "        myTree[bestFeatLabel][value] = creatDateTree(splitDateSet(dateSet,bestFeat,value),subLabels)\n",
    "    return myTree\n",
    "#测试决策树\n",
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstSide = list(inputTree.keys())\n",
    "    firstStr = firstSide[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:  #标签属性的值如果等于key\n",
    "            if type(secondDict[key]).__name__==\"dict\":\n",
    "                print(secondDict[key])\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel   \n",
    "#决策树的存储\n",
    "def storeTree(inputTree,filename):\n",
    "    fp =open(filename,\"wb\")\n",
    "    pickle.dump(inputTree,fp)\n",
    "    fp.close\n",
    "def grabTree(filename):\n",
    "    fp = open(filename,\"rb\")\n",
    "    return pickle.load(fp)\n",
    "if __name__ ==\"__main__\":\n",
    "    filename =\"F:\\\\python_daima\\\\KD_Tree\\\\glasses\\\\lenses.txt\"\n",
    "    fp = open(filename)\n",
    "    dateSet = [inst.strip().split(\"\\t\") for inst in fp.readlines()]\n",
    "    labels =[\"age\",\"prescript\",\"astigmatic\",\"tearRate\"]\n",
    "    myTree = creatDateTree(dateSet,labels)\n",
    "    print(myTree)\n",
    "    Label=classify(myTree,labels,[\"young\",\"myope\",\"no\",\"reduced\"])\n",
    "    print(Label)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
